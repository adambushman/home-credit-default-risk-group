---
title: "Modeling for Default"
author: "Adam Bushman"
date: "2024-10-20"
output: html_document
---

## Approach

I'm focusing on modeling for `TARGET` using the below method(s): 

1.  Penalized Regression


## Prep

Let's load a few libraries:

```{r}
library('tidyverse')
library('glmnet')
```

We'll load the cleaned, training data:

```{r}
data <- data.table::fread('data/application_train_clean.csv') |>
    as.data.frame()

glimpse(data)
```

All features in this file may conceivably be helpful in predicting `DEFAULT` (originally named `TARGET`), with exception of `SK_ID_CURR`. We do, however, have  little to no way of knowing which will be predictive. Therefore, an elastic net is probably the best choice.

Let's prepare the data:

```{r}
target <- data$DEFAULT
predictors <- as.matrix(
    data[,-which(names(data) %in% c("DEFAULT", "SK_ID_CURR"))]
)
```


## Basic Modeling

Let's run an elastic net model leveraging cross validation. We'll use the default 10 folds. The output we get will measure `AUC` and the standard error thereof.

```{r}
mod1 <- cv.glmnet(
    x = predictors, 
    y = target, 
    family = "binomial", 
    alpha = 0.5, 
    type.measure = "auc"
)

mod1
```

Using an elastic net model, we're achievingg an AUC of `~0.73` with a standard error of `0.0012` with 25 variables. 

```{r}
plot(mod1)
```

Let's look at the significant coefficients for the `1se` model since its VERY close to the absolute minimum in terms of performance:

```{r}
coef <- coef(mod1, "lambda.1se")
coef_df <- as.data.frame(as.matrix(coef))
coef_df$Predictor <- rownames(coef)
colnames(coef_df)[1] <- "Coefficient"

coef_df |>
    select(Predictor, Coefficient) |>
    arrange(desc(abs(Coefficient)))
```

## Tuned Modeling

The above, basic model assumes a perfect 50-50 elastic net. It could be, however, a better tuned model could improve performance. We test a few different values of `alpha` (the elastic net mix) to see if we can do any better. We will reduce the number of folds to help it run faster:

```{r}
mix <- seq(0.2, 0.8, 0.2)
results <- list()

for(m in mix) {
    t_mod <- cv.glmnet(
        x = predictors, 
        y = target, 
        family = "binomial", 
        nfolds = 3, 
        alpha = m, 
        type.measure = "auc"
    )

    results[[length(results) + 1]] <- c(m, t_mod$cvm[t_mod$index])
}
```

```{r}
df <- as.data.frame(do.call(rbind, my_list))
names(df) <- c("mix", "AUC_lambda.min", "AUC_lambda.1se")
df
```

We aren't achieving really any better or worse results with a weighted elastic net. The next step would be determining if some interaction terms could improve things.


## Interaction terms

We're going to create some interaction terms, something to indicate a varying relationship between predictors.

We'll implement the following interactions, largely informed by data analysis work and what was found above to be important predictors in estimating default:

1.  `CNT_CHILDREN` and `AMT_CREDIT`
2.  `AMT_ANNUITY` and `AMT_CREDIT`
3.  `DAYS_LAST_PHONE_CHANGE` and `AMT_REQ_CREDIT_BUREAU_DAY`
4.  `REGION_RATING_CLIENT_W_CITY` and `DEF_30_CNT_SOCIAL_CIRCLE`
5.  `AMT_REQ_CREDIT_BUREAU_DAY` and `AMT_CREDIT`
6.  `AMT_CREDIT` and `AMT_GOODS_PRICE`

```{r}
alt_data <-
    data |>
    mutate(
        I_CHILDREN_X_CREDIT = CNT_CHILDREN * AMT_CREDIT, 
        I_ANNUITY_X_CREDIT = AMT_ANNUITY * AMT_CREDIT, 
        I_PHONE_CHANGE_X_CREDIT_BUREAU_DAY = DAYS_LAST_PHONE_CHANGE * AMT_REQ_CREDIT_BUREAU_DAY, 
        I_REGION_RATING_X_30_SOCIAL = REGION_RATING_CLIENT_W_CITY * DEF_30_CNT_SOCIAL_CIRCLE, 
        I_BUREAU_DAY_X_CREDIT = AMT_REQ_CREDIT_BUREAU_DAY * AMT_CREDIT, 
        I_CREDIT_X_GOODS = AMT_CREDIT * AMT_GOODS_PRICE
    )
```

```{r}
predictors_alt <- as.matrix(
    alt_data[,-which(names(alt_data) %in% c("DEFAULT", "SK_ID_CURR"))]
)
```

Let's now use the interaction variables in another cross validated model:

```{r}
mod2 <- cv.glmnet(
    x = predictors_alt, 
    y = target, 
    family = "binomial", 
    alpha = 0.5, 
    type.measure = "auc"
)

mod2
```

The model really hasn't improved at all with inclusion of these interactions. Let's see if any of them show up as important predictors:

```{r}
coef <- coef(mod2, "lambda.1se")
coef_df <- as.data.frame(as.matrix(coef))
coef_df$Predictor <- rownames(coef)
colnames(coef_df)[1] <- "Coefficient"

coef_df |>
    select(Predictor, Coefficient) |>
    arrange(desc(abs(Coefficient)))
```

It looks as if the following were helpful predictors (though AUC was not improved):

*   `REGION_RATING_CLIENT_W_CITY` and `DEF_30_CNT_SOCIAL_CIRCLE`
*   `DAYS_LAST_PHONE_CHANGE` and `AMT_REQ_CREDIT_BUREAU_DAY`
*   `AMT_ANNUITY` and `AMT_CREDIT`
*   `AMT_CREDIT` and `AMT_GOODS_PRICE`


## Conclusion

There's too many unique relationships to explore for an optimal model in the OLS family, even with the penalized regression flavor. We're likely tapped-out with an AUC of **~0.73**.